{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-queensland",
   "metadata": {},
   "source": [
    "# Saving and Loading DataFrames\n",
    "\n",
    "In this guide, you will learn how to save and load Woodwork DataFrames.\n",
    "\n",
    "## Saving a Woodwork DataFrame\n",
    "\n",
    "After defining a Woodwork DataFrame with the proper logical types and semantic tags, you can save the DataFrame and  typing information by using `DataFrame.ww.to_disk`. By default, this method will create a directory that contains a `data` folder and a `woodwork_typing_info.json` file, but users have the ability to specify different values if needed. Refer to the [API Guide](https://woodwork.alteryx.com/en/stable/generated/woodwork.table_accessor.WoodworkTableAccessor.to_disk.html#woodwork.table_accessor.WoodworkTableAccessor.to_disk) for more information on the parameters that can be specified when using the `to_disk` method.\n",
    "\n",
    "To illustrate, we will use this retail DataFrame which already comes configured with Woodwork typing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-inventory",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from woodwork.demo import load_retail\n",
    "df = load_retail(nrows=100)\n",
    "df.ww.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-soccer",
   "metadata": {},
   "source": [
    "From the `ww` acessor, use `to_disk` to save the Woodwork DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ww.to_disk('retail')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-tactics",
   "metadata": {},
   "source": [
    "You should see a new directory that contains the data and typing information.\n",
    "\n",
    "```\n",
    "retail\n",
    "├── data\n",
    "│   └── demo_retail_data.csv\n",
    "└── woodwork_typing_info.json\n",
    "```\n",
    "\n",
    "### Data Directory\n",
    "\n",
    "The `data` directory contains the underlying data written in the specified format. If the user does not specify a filename, the method derives the filename from  `DataFrame.ww.name` and uses CSV as the default format. You can change the format by setting the method's `format` parameter to any of the following formats:\n",
    "\n",
    "- csv (default)\n",
    "- pickle\n",
    "- parquet\n",
    "- arrow\n",
    "- feather\n",
    "- orc\n",
    "\n",
    "### Typing Information\n",
    "\n",
    "In `woodwork_typing_info.json`, you can see all of the typing information and metadata associated with the DataFrame. This information includes:\n",
    "\n",
    "- the version of the schema at the time of saving the DataFrame\n",
    "- the DataFrame name specified by `DataFrame.ww.name`\n",
    "- the column names for the index and time index\n",
    "- the column typing information, which contains the logical types with their parameters and semantic tags for each column\n",
    "- the loading information required for the DataFrame type and file format\n",
    "- the table metadata provided by `DataFrame.ww.metadata` (must be JSON serializable)\n",
    "\n",
    "```text\n",
    "{\n",
    "    \"schema_version\": \"10.0.2\",\n",
    "    \"name\": \"demo_retail_data\",\n",
    "    \"index\": \"order_product_id\",\n",
    "    \"time_index\": \"order_date\",\n",
    "    \"column_typing_info\": [...],\n",
    "    \"loading_info\": {\n",
    "        \"table_type\": \"pandas\",\n",
    "        \"location\": \"data/demo_retail_data.csv\",\n",
    "        \"type\": \"csv\",\n",
    "        \"params\": {\n",
    "            \"compression\": null,\n",
    "            \"sep\": \",\",\n",
    "            \"encoding\": \"utf-8\",\n",
    "            \"engine\": \"python\",\n",
    "            \"index\": false\n",
    "        }\n",
    "    },\n",
    "    \"table_metadata\": {}\n",
    "}\n",
    "```\n",
    "\n",
    "## Loading a Woodwork DataFrame\n",
    "\n",
    "After saving a Woodwork DataFrame, you can load the DataFrame and typing information by using `woodwork.deserialize.from_disk`. This function will use the stored typing information in the specified directory to recreate the Woodwork DataFrame. \n",
    "\n",
    "If you have modified any of the default values for the filename, data subdirectory or typing information file, you will need to specify those when calling `from_disk`. Since we did not change any of the defaults for this example, we do not need to specify them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from woodwork.deserialize import from_disk\n",
    "df = from_disk('retail')\n",
    "df.ww.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-terrorism",
   "metadata": {},
   "source": [
    "### Loading the DataFrame and typing information separately\n",
    "\n",
    "You can also use `woodwork.read_file` to load a Woodwork DataFrame without the typing information. This approach is helpful if you want to quickly get started and let Woodwork infer the typing information based on the underlying data. To illustrate, let's read the CSV file from the previous example directly into a Woodwork DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "from woodwork import read_file\n",
    "\n",
    "df = read_file('retail/data/demo_retail_data.csv')\n",
    "df.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-liberty",
   "metadata": {},
   "source": [
    "The typing information is optional in `read_file`. So, you can still specify the typing information parameters to control how Woodwork gets initialized. To illustrate, we will read data files in different formats directly into a Woodwork DataFrame and use this typing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "typing_information = {\n",
    "    'index': 'order_product_id',\n",
    "    'time_index': 'order_date',\n",
    "    'logical_types': {\n",
    "        'order_product_id': 'Categorical',\n",
    "        'order_id': 'Categorical',\n",
    "        'product_id': 'Categorical',\n",
    "        'description': 'NaturalLanguage',\n",
    "        'quantity': 'Integer',\n",
    "        'order_date': 'Datetime',\n",
    "        'unit_price': 'Double',\n",
    "        'customer_name': 'Categorical',\n",
    "        'country': 'Categorical',\n",
    "        'total': 'Double',\n",
    "        'cancelled': 'Boolean',\n",
    "    },\n",
    "    'semantic_tags': {\n",
    "        'order_id': {'category'},\n",
    "        'product_id': {'category'},\n",
    "        'quantity': {'numeric'},\n",
    "        'unit_price': {'numeric'},\n",
    "        'customer_name': {'category'},\n",
    "        'country': {'category'},\n",
    "        'total': {'numeric'},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-bargain",
   "metadata": {},
   "source": [
    "First, let's create the data files in different formats from a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_df = pd.read_csv('retail/data/demo_retail_data.csv')\n",
    "pandas_df.to_csv('retail/data.csv')\n",
    "pandas_df.to_parquet('retail/data.parquet')\n",
    "pandas_df.to_feather('retail/data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-comfort",
   "metadata": {},
   "source": [
    "Now, you can use `read_file` to load the data directly into a Woodwork DataFrame based on your typing information. This function uses the `content_type` parameter to determine the file format. If `content_type` is not specified, it will try to infer the file format from the file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "woodwork_df = read_file(\n",
    "    filepath='retail/data.csv',\n",
    "    content_type='text/csv',\n",
    "    **typing_information,\n",
    ")\n",
    "\n",
    "woodwork_df = read_file(\n",
    "    filepath='retail/data.parquet',\n",
    "    content_type='application/parquet',\n",
    "    **typing_information,\n",
    ")\n",
    "\n",
    "woodwork_df = read_file(\n",
    "    filepath='retail/data.feather',\n",
    "    content_type='application/feather',\n",
    "    **typing_information,\n",
    ")\n",
    "\n",
    "woodwork_df.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-charlotte",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# cleanup retail directory\n",
    "from shutil import rmtree\n",
    "rmtree('retail')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}