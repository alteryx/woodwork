{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "later-pharmaceutical",
   "metadata": {},
   "source": [
    "# Understanding Logical Types and Semantic Tags\n",
    "\n",
    "In a Woodwork DataFrame, each column has three pieces of typing information associated with it: a physical type, a logical type, and semantic tags. \n",
    "\n",
    "This guide offers an in-depth walk-through of all of the logical types and semantic tags that Woodwork defines in order to allow users to choose the logical types and semantic tags that most closely describe their data. As a reminder, here are quick definitions of Woodwork's types:\n",
    "\n",
    "- Physical Type: defines how the data is stored on disk or in memory.\n",
    "- Logical Type: defines how the data should be parsed or interpreted.\n",
    "- Semantic Tag(s): provides additional data about the meaning of the data or how it should be used.\n",
    "\n",
    "Woodwork will attempt to infer a column's `LogicalType` if none is supplied at initialization. A column's logical type will then inform which physical type and standard semantic tags are applied to it. However, setting the types manually will allow for more accurate typing of a DataFrame.\n",
    "\n",
    "Having accurate typing information on a Woodwork DataFrame impacts how the data is parsed, transformed, and later interpreted downstream of Woodwork initialization. Therefore, understanding Woodwork's logical types and semantic tags is essential to downstream usage of Woodwork.\n",
    "\n",
    "For an in-depth guide on how to set and manipulate these types, see the [Working with Types and Tags](working_with_types_and_tags.ipynb) guide.\n",
    "\n",
    "For information on how to customize Woodwork's type system, see the [Custom Types and Inference](custom_types_and_type_inference.ipynb) guide.\n",
    "\n",
    "It's important to remember that Woodwork columns will always have a logical type and that any semantic tags that are added by Woodwork are meant to add additional meaning onto that logical type. We'll start out by looking in-depth at semantic tags so that when we get to logical types, we can better understand how a semantic tag might add additional information onto it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-strip",
   "metadata": {},
   "source": [
    "\n",
    "## Semantic Tags\n",
    "\n",
    "Here is the full set of Woodwork-defined semantic tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import woodwork as ww\n",
    "ww.list_semantic_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-husband",
   "metadata": {},
   "source": [
    "#### Standard Tags\n",
    "Standard tags are associated with specific logical types. They are useful for indicating predefined categories that logical types might fall into.\n",
    "\n",
    "- `'numeric'` - Is applied to any numeric logical type\n",
    "    - **Uses**: Can select for just numeric columns when performing operations that require numeric columns\n",
    "    - **Related Properties**: `series.ww.is_numeric`\n",
    "- `'category'` - Is applied to any logical type that is categorical in nature\n",
    "    - **Uses**: Can select for just categorical columns when performing operations that require categorical columns\n",
    "    - **Related Properties**: `series.ww.is_categorical`\n",
    "\n",
    "#### Index Tags\n",
    "Index tags are added by Woodwork to a DataFrame when an `index` or `time_index` column is identified by the user. These tags have some special properties that are only confirmed to be true in the context of a DataFrame (so any Series with these tags may not have these properties).\n",
    "\n",
    "- `'index'` - Indicates that a column is the DataFrame's index, or primary key\n",
    "    - There will only be one index column\n",
    "    - The contents of an index column will be unique\n",
    "    - An index column will have any standard semantic tags associated with its logical type removed\n",
    "    - In pandas DataFrames, the data in an index column will be reflected in the DataFrame's underlying index\n",
    "- `'time_index'`\n",
    "    - There will only be one time index column\n",
    "    - A time index column will contain either datetime or numeric data\n",
    "\n",
    "#### Other Tags\n",
    "The tags listed below may be added directly to columns during or after Woodwork initialization. They are tags that have suggested meanings and that can be added to columns that will be used in the manner described below. Woodwork will neither add them automatically to a DataFrame nor take direct action upon a column if they are present. \n",
    "\n",
    "- `'date_of_birth'` - Indicates that a datetime column should be parsed as a date of birth\n",
    "- `'ignore'`/`'passthrough'` - Indicates that a column should be ignored during feature engineering or model building but should still be passed through these operations so that the column is not lost.\n",
    "\n",
    "Additional tags beyond the ones Woodwork adds at initialization may be useful for a DataFrame's interpretability, so users are encouraged to add any tags that will allow them to use their data more efficiently. \n",
    "\n",
    "## Logical Types\n",
    "\n",
    "Below are all of the Logical Types that Woodwork defines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import woodwork as ww\n",
    "ww.list_logical_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-greek",
   "metadata": {},
   "source": [
    "In the DataFrame above, we can see a `parent_type` column. The `parent_type` of a `LogicalType` refers to a logical type that is a more general version of the current `LogicalType`. See the [Custom Types and Type Inference](custom_types_and_type_inference.ipynb#Logical-Type-Relationships) guide for more details on how parent-child relationships between logical types impacts Woodwork's type inference.\n",
    "\n",
    "#### Base LogicalType Class\n",
    "\n",
    "All logical types used by Woodwork are subclassed off of the base `LogicalType` class, and since the following behaviors all exist on the `LogicalType` class, all logical types have the following behavior:\n",
    "\n",
    "- All logical types define a `dtype` that will get used for any column with that logical type - this is how the physical type for a column gets determined\n",
    "- All logical types perform some basic transformation into the expected physical type (`dtype`) - this is how Woodwork LogicalTypes act as a form of data-transformers. Depending on the requirements of a LogicalType, a LogicalType can transform input data into an expected format. \n",
    "\n",
    "    ```python\n",
    "    class LogicalType(object, metaclass=LogicalTypeMetaClass):\n",
    "        \"\"\"Base class for all other Logical Types\"\"\"\n",
    "        type_string = ClassNameDescriptor()\n",
    "        primary_dtype = 'string'\n",
    "        backup_dtype = None\n",
    "        standard_tags = set()\n",
    "    ```\n",
    "\n",
    "#### Default Logical Type\n",
    "\n",
    "##### Unknown\n",
    "When Woodwork's type inference does not return any LogicalTypes for a column, Woodwork will set the column's logical type as the default LogicalType, `Unknown`. A logical type being inferred as `Unknown` may be a good indicator that a more specific logical type can be chosen and set by the user.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "Below is an example of a column for which no logical type is inferred, resulting in a Series with `Unknown` logical type. Looking at the contents of the Series, though, we can see that it contains country codes, so we set the logical type to `CountryCode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"AU\", \"US\", \"UA\"])\n",
    "unknown_series = ww.init_series(series)\n",
    "unknown_series.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "countrycode_series = ww.init_series(unknown_series, 'CountryCode')\n",
    "countrycode_series.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-marketing",
   "metadata": {},
   "source": [
    "#### Numeric Logical Types\n",
    "\n",
    "##### Age\n",
    "\n",
    "Represents Logical Types that contain whole numbers indicating a person’s age.\n",
    "\n",
    "- **physical type**: `int64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "##### AgeFractional\n",
    "\n",
    "Represents Logical Types that contain non-negative floating point numbers indicating a person’s age. May contain null values.\n",
    "\n",
    "- **physical type**: `float64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "\n",
    "##### AgeNullable\n",
    "\n",
    "Represents Logical Types that contain whole numbers indicating a person’s age. May contain null values.\n",
    "\n",
    "- **physical type**: `Int64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "##### Double\n",
    "\n",
    "Represents Logical Types that contain positive and negative numbers, some of which include a fractional component.\n",
    "\n",
    "- **physical type**: `float64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "##### Integer\n",
    "\n",
    "Represents Logical Types that contain positive and negative numbers without a fractional component, including zero (0).\n",
    "\n",
    "- **physical type**: `int64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "##### IntegerNullable \n",
    "Represents Logical Types that contain positive and negative numbers without a fractional component, including zero (0). May contain null values. \n",
    "\n",
    "- **physical type**: `Int64`\n",
    "- **standard tags**: `{'numeric'}`\n",
    "\n",
    "\n",
    "\n",
    "Below we'll find a dataframe with examples of each of the numeric LogicalTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_df = pd.DataFrame({\n",
    "    'ints' : [1, 2, 3, 4],\n",
    "    'ints_nullable': pd.Series([1, 2, None, 4], dtype='Int64'),\n",
    "    'floats' : [0.0, 1.1, 2.2, 3.3],\n",
    "    'ages': [18, 22, 24, 34],\n",
    "    'ages_nullable' : [None, 2, 22, 33]\n",
    "})\n",
    "\n",
    "numerics_df.ww.init(logical_types={'ages':'Age', 'ages_nullable':'AgeNullable'})\n",
    "numerics_df.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-banks",
   "metadata": {},
   "source": [
    "#### Categorical Logical Types\n",
    "\n",
    "##### Categorical \n",
    "\n",
    "Represents a Logical Type with few unique values relative to the size of the data.\n",
    "\n",
    "- **physical type**: `category`\n",
    "- **inference**: Woodwork defines a threshold for percentage unique values relative to the size of the series below which a series will be considered categorical. See [setting config options guide](setting_config_options.ipynb#Categorical-Threshold) for more information on how to control this threshold.\n",
    "- **spark note**: Spark does not support the `category` dtype, so for Spark DataFrames and Series, the `string` dtype will be used.\n",
    "\n",
    "\n",
    "Some examples of data for which the Categorical logical type would apply:\n",
    "\n",
    "- Gender\n",
    "- Eye Color\n",
    "- Nationality\n",
    "- Hair Color\n",
    "- Spoken Language\n",
    "\n",
    "##### CountryCode\n",
    "\n",
    "Represents Logical Types that use the ISO-3166 standard country code to represent countries. ISO 3166-1 (countries) are supported. These codes should be in the Alpha-2 format.\n",
    "\n",
    "- **physical type**: `category`\n",
    "- **standard tags**: `{'category'}`\n",
    "- **spark note**: Spark does not support the `category` dtype, so for Spark DataFrames and Series, the `string` dtype will be used.\n",
    "\n",
    "For example: `'AU'` for Australia, `'CN'` for China, and `'CA'` for Canada.\n",
    "\n",
    "##### Ordinal\n",
    "\n",
    "A Ordinal variable type can take ordered discrete values. Similar to Categorical, it is usually a limited, and fixed number of possible values. However, these discrete values have a certain order, and the ordering is important to understanding the values. Ordinal variable types can be represented as strings, or integers. \n",
    "\n",
    "- **physical type**: `category`\n",
    "- **standard tags**: `{'category'}`\n",
    "- **parameters**:\n",
    "    - `order` - the order of the ordinal values in the column from low to high\n",
    "- **validation** - an order must be defined for an Ordinal column on a DataFrame or Series, and all elements of the order must be present.\n",
    "- **spark note**: Spark does not support the `category` dtype, so for Spark DataFrames and Series, the `string` dtype will be used.\n",
    "\n",
    "Some examples of data for which the Ordinal logical type would apply:\n",
    "\n",
    "- Educational Background (Elementary, High School, Undergraduate, Graduate)\n",
    "- Satisfaction Rating (Not Satisfied, Satisfied, Very Satisfied)\n",
    "- Spicy Level (Hot, Hotter, Hottest)\n",
    "- Student Grade (A, B, C, D, F)\n",
    "- Size (small, medium, large)\n",
    "\n",
    "##### PostalCode\n",
    "\n",
    "Represents Logical Types that contain a series of postal codes for representing a group of addresses.\n",
    "\n",
    "- **physical type**: `category`\n",
    "- **standard tags**: `{'category'}`\n",
    "- **spark note**: Spark does not support the `category` dtype, so for Spark DataFrames and Series, the `string` dtype will be used.\n",
    "\n",
    "##### SubRegionCode\n",
    "\n",
    "Represents Logical Types that use the ISO-3166 standard sub-region code to represent a portion of a larger geographic region. ISO 3166-2 (sub-regions) codes are supported. These codes should be in the Alpha-2 format.\n",
    "\n",
    "- **physical type**: `category`\n",
    "- **standard tags**: `{'category'}`\n",
    "- **spark note**: Spark does not support the `category` dtype, so for Spark DataFrames and Series, the `string` dtype will be used.\n",
    "\n",
    "For example: `'US-IL'` to represent Illinois in the United States or `'AU-TAS'` to represent Tasmania in Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_df = pd.DataFrame({\n",
    "    'categorical': pd.Series(['a', 'b', 'a', 'a'], dtype='category'),\n",
    "    'ordinal' : ['small', 'large', 'large', 'medium'],\n",
    "    'country_code' : [\"AU\", \"US\", \"UA\", \"AU\"],\n",
    "    'postal_code': [\"90210\", \"60035\", \"SW1A\", \"90210\" ],\n",
    "    'sub_region_code' : [\"AU-NSW\", \"AU-TAS\", \"AU-QLD\", \"AU-QLD\"]\n",
    "})\n",
    "categoricals_df.ww.init(logical_types={'ordinal':ww.logical_types.Ordinal(order=['small', 'medium', 'large']),\n",
    "                                       'country_code':'CountryCode', \n",
    "                                       'postal_code':'PostalCode',\n",
    "                                       'sub_region_code':'SubRegionCode'})\n",
    "\n",
    "categoricals_df.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-saying",
   "metadata": {},
   "source": [
    "#### Miscellaneous Logical Types with Specific Formats\n",
    "\n",
    "##### Boolean\n",
    "\n",
    "Represents Logical Types that contain binary values indicating true/false.\n",
    "\n",
    "- **physical type**: `bool`\n",
    "\n",
    "##### BooleanNullable\n",
    "Represents Logical Types that contain binary values indicating true/false. May also contain null values.\n",
    "\n",
    "- **physical type**: `boolean`\n",
    "\n",
    "##### Datetime\n",
    "A Datetime is a representation of a date and/or time. Datetime variable types can be represented as strings, or integers.\n",
    "\n",
    "- **physical type**: `datetime64[ns]`\n",
    "- **transformation**: Will convert valid strings or numbers to pandas datetimes, and will parse more datetime formats with the use of the `datetime_format` parameter.\n",
    "- **parameters**:\n",
    "    - `datetime_format` - the format of the datetimes in the column, ex: `'%Y-%m-%d'` vs `'%m-%d-%Y'`\n",
    "\n",
    "Some examples of Datetime include:\n",
    "\n",
    "- Transaction Time\n",
    "- Flight Departure Time\n",
    "- Pickup Time\n",
    "\n",
    "##### EmailAddress\n",
    "\n",
    "Represents Logical Types that contain email address values.\n",
    "\n",
    "- **physical type**: `string`\n",
    "- **inference**: Uses an email address regex that, if the data matches, means that the column contains email addresses. To learn more about controling the regex used, see the [setting config options guide](setting_config_options.ipynb#Email-Inference-Regex).\n",
    "\n",
    "##### LatLong\n",
    "A LatLong represents an ordered pair (Latitude, Longitude) that tells the location on Earth. The order of the tuple is important. LatLongs can be represented as tuple of floating point numbers. \n",
    "\n",
    "- **physical type**: `object`\n",
    "- **transformation**: Will convert inputs into a tuple of floats. Any null values will be stored as `np.nan`\n",
    "- **spark note**: Spark does not support tuples, so latlongs will be stored as a list of floats\n",
    "\n",
    "##### Timedelta\n",
    "\n",
    "Represents Logical Types that contain values specifying a duration of time.\n",
    "\n",
    "- **physical type**: `timedelta64[ns]`\n",
    "\n",
    "\n",
    "Examples could inclue:\n",
    "\n",
    "- Days/months/years since some event\n",
    "- How long a flight's arrival was delayed/early\n",
    "- Days until birthday\n",
    "\n",
    "Below, we'll see a DataFrame that contains data for each of these logical types. Some columns like `dates` and `latlongs` will have their data transformed to a format that Woodwork expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'dates': [\"2019/01/01\", \"2019/01/02\", \"2019/01/03\", \"2019/01/03\"],\n",
    "    'latlongs': ['[33.670914, -117.841501]', '40.423599, -86.921162', (-45.031705, None), None],\n",
    "    'booleans': [True, True, False, True],\n",
    "    'bools_nullable': pd.Series([True, False, True, None], dtype='boolean'),\n",
    "    'timedelta': [pd.Timedelta('1 days 00:00:00'), pd.Timedelta('-1 days +23:40:00'),\n",
    "             pd.Timedelta('4 days 12:00:00'), pd.Timedelta('-1 days +23:40:00')],\n",
    "    'emails':[\"john.smith@example.com\", \"support@example.com\", \"team@example.com\", \"help@example.com\"]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ww.init(logical_types={'latlongs':'LatLong',\n",
    "                          'dates':ww.logical_types.Datetime(datetime_format='%Y/%m/%d')})\n",
    "df.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-singapore",
   "metadata": {},
   "source": [
    "#### String Logical Types\n",
    "\n",
    "##### NaturalLanguage\n",
    "\n",
    "Represents Logical Types that contain long-form text or characters representing natural human language\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "Examples of natural language data:\n",
    "\n",
    "- \"Any additional comments\" in a feedback form\n",
    "- Customer Review\n",
    "- Patient Notes\n",
    "\n",
    "##### Address\n",
    "\n",
    "Represents Logical Types that contain address values.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "\n",
    "##### Filepath\n",
    "\n",
    "Represents Logical Types that specify locations of directories and files in a file system.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "\n",
    "##### PersonFullName\n",
    "\n",
    "Represents Logical Types that may contain first, middle and last names, including honorifics and suffixes.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "##### PhoneNumber\n",
    "\n",
    "Represents Logical Types that contain numeric digits and characters representing a phone number.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "\n",
    "##### URL\n",
    "\n",
    "Represents Logical Types that contain URLs, which may include protocol, hostname and file name.\n",
    "\n",
    "- **physical type**: `string`\n",
    "\n",
    "##### IPAddress\n",
    "\n",
    "Represents Logical Types that contain IP addresses, including both IPv4 and IPv6 addresses.\n",
    "\n",
    "- **physical type**: `string`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_df = pd.DataFrame({\n",
    "    'natural_language':[\"This is a short sentence.\",\n",
    "                         \"I like to eat pizza!\",\n",
    "                         \"When will humans go to mars?\",\n",
    "                         \"This entry contains two sentences. Second sentence.\"],\n",
    "    'addresses':['1 Miller Drive, New York, NY 12345', '1 Berkeley Street, Boston, MA 67891',\n",
    "                '26387 Russell Hill, Dallas, TX 34521', '54305 Oxford Street, Seattle, WA 95132'],\n",
    "    'filepaths':[\"/usr/local/bin\",\n",
    "                 \"/Users/john.smith/dev/index.html\",\n",
    "                 \"/tmp\",\n",
    "                 \"../woodwork\"],\n",
    "    'full_names':[\"Mr. John Doe, Jr.\",\n",
    "                 \"Doe, Mrs. Jane\",\n",
    "                 \"James Brown\",\n",
    "                 \"John Smith\"],\n",
    "    'phone_numbers':[\"1-(555)-123-5495\",\n",
    "                     \"+1-555-123-5495\",\n",
    "                     \"5551235495\",\n",
    "                     \"111-222-3333\"],\n",
    "    'urls': [\"http://google.com\",\n",
    "             \"https://example.com/index.html\",\n",
    "             \"example.com\",\n",
    "             \"https://woodwork.alteryx.com/\"],\n",
    "    'ip_addresses': [\"172.16.254.1\",\n",
    "                     \"192.0.0.0\",\n",
    "                     \"2001:0db8:0000:0000:0000:ff00:0042:8329\",\n",
    "                     \"192.0.0.0\"],\n",
    "})\n",
    "strings_df.ww.init(logical_types={\n",
    "    'natural_language':'NaturalLanguage',\n",
    "    'addresses':'Address',\n",
    "    'filepaths':'FilePath',\n",
    "    'full_names':'PersonFullName',\n",
    "    'phone_numbers':'PhoneNumber',\n",
    "    'urls':'URL',\n",
    "    'ip_addresses':'IPAddress',\n",
    "})\n",
    "strings_df.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-delta",
   "metadata": {},
   "source": [
    "## ColumnSchema objects\n",
    "\n",
    "Now that we've gone in-depth on semantic tags and logical types, we can start to understand how they're used together to build Woodwork tables and define type spaces.\n",
    "\n",
    "A `ColumnSchema` is the typing information for a single column. We can obtain a `ColumnSchema` from a Woodwork-initialized DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woodwork typing info for a DataFrame\n",
    "retail_df = ww.demo.load_retail()\n",
    "retail_df.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-slovenia",
   "metadata": {},
   "source": [
    "Above is the typing information for a Woodwork DataFrame. If we want, we can access just the schema of typing information outside of the context of the actual data in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Woodwork TableSchema\n",
    "retail_df.ww.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-payment",
   "metadata": {},
   "source": [
    "The representation of the `woodwork.table_schema.TableSchema` is only different in that it does not have a column for the physical types.\n",
    "\n",
    "This lack of a physical type is due to the fact that a `TableSchema` has no data, and therefore no physical representation of the data. We often rely on physical typing information to know the exact pandas or Dask or Spark operations that are valid for a DataFrame, but for a schema of typing information that is not tied to data, those operations are not relevant.\n",
    "\n",
    "Now, let's look at a single column of typing information, or a `woodwork.column_schema.ColumnSchema` that we can aquire in much the same way as we can select a Series from the DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woodwork typing infor for a Series\n",
    "quantity = retail_df.ww['quantity']\n",
    "quantity.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Woodwork ColumnSchema\n",
    "quantity_schema = quantity.ww.schema\n",
    "quantity_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-slovenia",
   "metadata": {},
   "source": [
    "The `column_schema` object above can be understood as typing information for a single column that is not tied to any data. In this case, we happen to know where the column schema came from - it was the `quantity` column from the `retail_df` DataFrame. But we can also create a `ColumnSchema` that exists without being associated with any individual column of data.\n",
    "\n",
    "If we look again at the `retail_df` table as a whole, we can see the similarities and differences between the columns, and we can describe those subsets of the DataFrame with `ColumnSchema` objects, or type spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.ww.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-wireless",
   "metadata": {},
   "source": [
    "Below are several `ColumnSchema`s that all would include our `quantity` column, but each of them describe a different type space. These `ColumnSchema`s get more restrictive as we go down:\n",
    "\n",
    "- `<ColumnSchema >` - No restrictions have been placed; any column falls into this definition.\n",
    "- `<ColumnSchema (Semantic Tags = ['numeric'])>` - Only columns with the `numeric` tag apply. This can include Double, Integer, and Age logical type columns as well.\n",
    "- `<ColumnSchema (Logical Type = Integer)>` - Only columns with logical type of `Integer` are included in this definition. Does not require the `numeric` tag, so an index column (which has its standard tags removed) would still apply\n",
    "- `<ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>` - The column must have logical type `Integer` and have the `numeric` semantic tag, excluding index columns.\n",
    "\n",
    "In this way, a `ColumnSchema` can define a type space under which columns in a Woodwork DataFrame can fall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-adoption",
   "metadata": {},
   "source": [
    "## Checking for nullable logical types\n",
    "\n",
    "Some logical types support having null values in the underlying data while others do not.  This is entirely based on whether a logical type's underlying primary dtype or backup dtype supports null values.  For example, the `EmailAddress` logical type has an underlying primary dtype of `string`.  Pandas allows series with the dtype `string` to contain null values marked by the `pandas.NA` sentinel.  Therefore, `EmailAddress` supports null values.  On the other hand, the `Integer` logical type does not support null values since its underlying primary pandas dtype is `int64`.  Pandas does not allow null values in series with the dtype `int64`.  However, pandas does allow null values in series with the dtype `Int64`.  Therefore, the `IntegerNullable` logical type supports null values since its primary dtype is `Int64`.\n",
    "\n",
    "You can check if a column contains a nullable logical type by using `nullable` on the column accessor.  The sections above that describe each type's characteristics include information about whether or not a logical type is nullable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ww['bools_nullable'].ww.nullable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
